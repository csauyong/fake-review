{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fake Movie Review Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To build the dataset, we will first scrape reviews of Joker, a 2019 film whose reviews are abundant and diverse in opinion, from professional critics on Rotten Tomatoes using Selenium. The collected reviews will be labelled as genuine since the identity of the critics are verified and highly credible. We then pass the genuine reviews collected into a text generation AI, namely GPT-2, to produce fake reviews while preserving the positive-negative ratio. We will eventually obtain a class-balanced dataset with half genuine and half fake reviews, where each record contains the review text and an indicator of whether it likes the movie."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scrape Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Source: https://stackoverflow.com/questions/69963743/scraping-all-reviews-of-a-movie-from-rotten-tomato-using-soup\n",
    "'''\n",
    "import pandas as pd\n",
    "import requests\n",
    "import re\n",
    "import time\n",
    "\n",
    "headers = {\n",
    "    'Referer': 'https://www.rottentomatoes.com/m/notebook/reviews?type=user',\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/74.0.3729.108 Safari/537.36',\n",
    "    'X-Requested-With': 'XMLHttpRequest',\n",
    "}\n",
    "\n",
    "s = requests.Session()\n",
    "        \n",
    "def get_reviews(url):\n",
    "    r = requests.get(url)\n",
    "    movie_id = re.findall(r'(?<=movieId\":\")(.*)(?=\",\"type)',r.text)[0]\n",
    "\n",
    "    api_url = f\"https://www.rottentomatoes.com/napi/movie/{movie_id}/criticsReviews/all\" #use reviews/userfor user reviews\n",
    "    \n",
    "    payload = {\n",
    "        'direction': 'next',\n",
    "        'endCursor': '',\n",
    "        'startCursor': '',\n",
    "    }\n",
    "    \n",
    "    review_data = []\n",
    "    \n",
    "    while True:\n",
    "        r = s.get(api_url, headers=headers, params=payload)\n",
    "        data = r.json()\n",
    "        print(data['pageInfo'])\n",
    "\n",
    "        if data['pageInfo']['hasNextPage']:\n",
    "            payload['endCursor'] = data['pageInfo']['endCursor']\n",
    "            payload['startCursor'] = data['pageInfo']['startCursor'] if data['pageInfo'].get('startCursor') else ''\n",
    "\n",
    "        review_data.extend(data['reviews'])\n",
    "        \n",
    "        if not data['pageInfo']['hasNextPage']:\n",
    "            break\n",
    "        \n",
    "        time.sleep(1)\n",
    "    \n",
    "    return review_data\n",
    "\n",
    "data = get_reviews('https://www.rottentomatoes.com/m/joker_2019/reviews')\n",
    "df = pd.json_normalize(data)\n",
    "df.to_csv('critic_reviews.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import html\n",
    "\n",
    "df = pd.read_csv(\"critic_reviews_complete.csv\")\n",
    "quotes = df.apply(lambda row : html.unescape(row['quote']),axis=1)\n",
    "info = df[['isFresh','scoreOri']]\n",
    "\n",
    "cleaned = pd.concat([info, quotes], axis=1)\n",
    "cleaned.to_csv(\"cleaned.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
